<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Multimodal Emotion Detection</title>
  <style>
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      margin: 0;
      padding: 20px;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      min-height: 100vh;
      color: white;
    }
    .container {
      max-width: 1200px;
      margin: 0 auto;
      background: rgba(255, 255, 255, 0.1);
      padding: 30px;
      border-radius: 20px;
      backdrop-filter: blur(10px);
      box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
    }
    h1 {
      text-align: center;
      margin-bottom: 30px;
      font-size: 2.5em;
      text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
    }
    .controls {
      text-align: center;
      margin-bottom: 30px;
    }
    button {
      background: linear-gradient(45deg, #ff6b6b, #ee5a24);
      border: none;
      color: white;
      padding: 15px 30px;
      margin: 0 10px;
      border-radius: 25px;
      cursor: pointer;
      font-size: 16px;
      font-weight: bold;
      transition: all 0.3s ease;
      box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
    }
    button:hover {
      transform: translateY(-2px);
      box-shadow: 0 6px 20px rgba(0, 0, 0, 0.3);
    }
    button:disabled {
      background: #95a5a6;
      cursor: not-allowed;
      transform: none;
    }
    .video-container {
      display: flex;
      gap: 30px;
      margin-bottom: 30px;
      flex-wrap: wrap;
    }
    .video-section {
      flex: 1;
      min-width: 300px;
    }
    video {
      width: 100%;
      max-width: 400px;
      border-radius: 15px;
      box-shadow: 0 8px 25px rgba(0, 0, 0, 0.3);
    }
    .emotions-display {
      display: flex;
      gap: 30px;
      margin-bottom: 30px;
      flex-wrap: wrap;
    }
    .emotion-panel {
      flex: 1;
      min-width: 300px;
      background: rgba(255, 255, 255, 0.1);
      padding: 20px;
      border-radius: 15px;
      backdrop-filter: blur(5px);
    }
    .emotion-panel h3 {
      margin-top: 0;
      color: #fff;
      text-align: center;
      font-size: 1.3em;
    }
    .emotion-bar {
      margin-bottom: 10px;
      background: rgba(255, 255, 255, 0.2);
      border-radius: 10px;
      overflow: hidden;
    }
    .emotion-bar-fill {
      height: 25px;
      background: linear-gradient(45deg, #4ecdc4, #44a08d);
      transition: width 0.15s ease;
      display: flex;
      align-items: center;
      padding-left: 10px;
      color: white;
      font-weight: bold;
      font-size: 12px;
    }
    .status {
      text-align: center;
      padding: 15px;
      background: rgba(0, 0, 0, 0.3);
      border-radius: 10px;
      margin: 20px 0;
    }
    .summary {
      background: rgba(255, 255, 255, 0.15);
      padding: 30px;
      border-radius: 15px;
      margin-top: 30px;
      backdrop-filter: blur(10px);
    }
    .summary h2 {
      text-align: center;
      margin-bottom: 30px;
      color: #fff;
    }
    .summary-grid {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 30px;
    }
    .summary-section {
      background: rgba(255, 255, 255, 0.1);
      padding: 20px;
      border-radius: 10px;
    }
    .summary-section h3 {
      text-align: center;
      margin-bottom: 15px;
      color: #fff;
    }
    .summary-item {
      display: flex;
      justify-content: space-between;
      margin-bottom: 8px;
      padding: 5px 0;
      border-bottom: 1px solid rgba(255, 255, 255, 0.1);
    }
    .hidden {
      display: none;
    }
    @media (max-width: 768px) {
      .summary-grid {
        grid-template-columns: 1fr;
      }
      .video-container,
      .emotions-display {
        flex-direction: column;
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>ðŸŽ­ Multimodal Emotion Detection</h1>
    <div class="controls">
      <button id="startBtn">Start Detection</button>
      <button id="stopBtn" disabled>Stop Detection</button>
    </div>
    <div class="status" id="status">
      Click "Start Detection" to begin analyzing emotions from camera and microphone
    </div>
    <div class="video-container">
      <div class="video-section">
        <video id="video" autoplay muted playsinline></video>
      </div>
    </div>
    <div class="emotions-display">
      <div class="emotion-panel">
        <h3>ðŸ˜Š Facial Emotions (Real-time)</h3>
        <div id="faceEmotions"></div>
      </div>
      <div class="emotion-panel">
        <h3>ðŸŽ¤ Voice Emotions (Real-time)</h3>
        <div id="voiceEmotions"></div>
      </div>
    </div>
    <div class="summary hidden" id="summary">
      <h2>ðŸ“Š Final Emotion Summary</h2>
      <div class="summary-grid">
        <div class="summary-section">
          <h3>Facial Analysis</h3>
          <div id="faceSummary"></div>
        </div>
        <div class="summary-section">
          <h3>Voice Analysis</h3>
          <div id="voiceSummary"></div>
        </div>
      </div>
    </div>
  </div>

  <script>
    const video = document.getElementById('video');
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const status = document.getElementById('status');
    const faceEmotions = document.getElementById('faceEmotions');
    const voiceEmotions = document.getElementById('voiceEmotions');
    const summary = document.getElementById('summary');
    const faceSummary = document.getElementById('faceSummary');
    const voiceSummary = document.getElementById('voiceSummary');

    let ws = null;
    let stream = null;
    let audioContext = null;
    let scriptNode = null;
    let sessionActive = false;
    let animationFrameId = null;
    let connectionAttempts = 0;
    const maxConnectionAttempts = 3;

    const emotions = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral'];

    function initEmotionDisplays() {
      emotions.forEach(emotion => {
        const faceBar = document.createElement('div');
        faceBar.className = 'emotion-bar';
        faceBar.innerHTML = `<div class="emotion-bar-fill" id="face-${emotion}" style="width: 0%">${emotion}: 0%</div>`;
        faceEmotions.appendChild(faceBar);

        const voiceBar = document.createElement('div');
        voiceBar.className = 'emotion-bar';
        voiceBar.innerHTML = `<div class="emotion-bar-fill" id="voice-${emotion}" style="width: 0%">${emotion}: 0%</div>`;
        voiceEmotions.appendChild(voiceBar);
      });
    }

    function updateEmotionDisplay(type, emotionScores) {
      let totalScore = Object.values(emotionScores).reduce((sum, val) => sum + val, 0);
      if (totalScore <= 0) totalScore = 1;

      emotions.forEach(emotion => {
        let score = emotionScores[emotion] || 0;
        score = (score / totalScore) * 100;
        const element = document.getElementById(`${type}-${emotion}`);
        if (element) {
          element.style.width = `${score.toFixed(1)}%`;
          element.textContent = `${emotion}: ${score.toFixed(1)}%`;
        }
      });
    }

    function connectWebSocket() {
      // For Render deployment, always use wss:// for secure WebSocket connections
      const isLocalhost = ['localhost', '127.0.0.1'].includes(window.location.hostname);
      const protocol = isLocalhost && window.location.protocol === 'http:' ? 'ws://' : 'wss://';
      const wsUrl = `${protocol}${window.location.host}/ws`;
      
      console.log('Attempting WebSocket connection to:', wsUrl);
      connectionAttempts++;
      
      ws = new WebSocket(wsUrl);

      ws.onopen = () => {
        console.log('WebSocket connected successfully');
        connectionAttempts = 0; // Reset on successful connection
        if (sessionActive) {
          ws.send(JSON.stringify({ type: 'start_session' }));
          status.textContent = 'Recording started - analyzing emotions...';
          processVideo();
        }
      };

      ws.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data);
          switch(data.type) {
            case 'session_started':
              status.textContent = 'Recording started - analyzing emotions...';
              break;
            case 'face_emotion':
              updateEmotionDisplay('face', data.emotions);
              break;
            case 'voice_emotion':
              updateEmotionDisplay('voice', data.emotions);
              break;
            case 'final_summary':
              showFinalSummary(data);
              stopDetection();
              break;
          }
        } catch (e) {
          console.error('Error processing WebSocket message:', e);
        }
      };

      ws.onerror = (error) => {
        console.error('WebSocket error:', error);
        status.textContent = `Connection error (attempt ${connectionAttempts}/${maxConnectionAttempts}). ${connectionAttempts < maxConnectionAttempts ? 'Retrying...' : 'Please refresh the page.'}`;
        
        if (connectionAttempts < maxConnectionAttempts && sessionActive) {
          setTimeout(() => {
            connectWebSocket();
          }, 2000); // Retry after 2 seconds
        } else {
          stopDetection();
        }
      };

      ws.onclose = (event) => {
        console.log('WebSocket disconnected:', event.code, event.reason);
        if (sessionActive && connectionAttempts < maxConnectionAttempts) {
          status.textContent = `Connection lost (attempt ${connectionAttempts}/${maxConnectionAttempts}). Reconnecting...`;
          setTimeout(() => {
            connectWebSocket();
          }, 2000);
        } else if (sessionActive) {
          status.textContent = 'Connection lost. Please try again.';
          stopDetection();
        }
      };
    }

    function showFinalSummary(data) {
      faceSummary.innerHTML = '';
      voiceSummary.innerHTML = '';

      if (data.face_emotions) {
        Object.entries(data.face_emotions).forEach(([emotion, percentage]) => {
          const item = document.createElement('div');
          item.className = 'summary-item';
          item.innerHTML = `<span>${emotion}:</span><span>${percentage.toFixed(1)}%</span>`;
          faceSummary.appendChild(item);
        });
      }

      if (data.voice_emotions) {
        Object.entries(data.voice_emotions).forEach(([emotion, percentage]) => {
          const item = document.createElement('div');
          item.className = 'summary-item';
          item.innerHTML = `<span>${emotion}:</span><span>${percentage.toFixed(1)}%</span>`;
          voiceSummary.appendChild(item);
        });
      }

      summary.classList.remove('hidden');
      status.textContent = 'Analysis complete! Check the summary below.';
    }

    async function startDetection() {
      // More permissive HTTPS check for deployment
      const isSecure = window.location.protocol === 'https:' || 
                       ['localhost', '127.0.0.1'].includes(window.location.hostname);
      
      if (!isSecure) {
        status.textContent = 'Camera/mic access requires HTTPS. Please use HTTPS URL.';
        return;
      }

      try {
        status.textContent = 'Requesting camera and microphone access...';

        stream = await navigator.mediaDevices.getUserMedia({
          video: {
            width: { ideal: 640 },
            height: { ideal: 480 },
            facingMode: 'user'
          },
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            sampleRate: 16000,
            channelCount: 1
          }
        });

        video.srcObject = stream;
        sessionActive = true;
        connectionAttempts = 0; // Reset connection attempts

        // Initialize audio context
        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
        
        // Try AudioWorklet first, fall back to ScriptProcessor
        try {
          await audioContext.audioWorklet.addModule('/static/audio-processor.js');
          setupAudioWorklet();
        } catch (e) {
          console.warn('AudioWorklet not available, falling back to ScriptProcessor:', e);
          setupScriptProcessor();
        }

        connectWebSocket();

        startBtn.disabled = true;
        stopBtn.disabled = false;
        summary.classList.add('hidden');
      } catch (error) {
        console.error('Error starting detection:', error);
        status.textContent = 'Error accessing camera/microphone. Please grant permissions and ensure HTTPS.';
        stopDetection();
      }
    }

    function setupAudioWorklet() {
      const source = audioContext.createMediaStreamSource(stream);
      const workletNode = new AudioWorkletNode(audioContext, 'audio-processor');

      workletNode.port.onmessage = function(event) {
        if (!sessionActive) return;

        const { type, data } = event.data;
        if (type === 'audio_chunk' && ws && ws.readyState === WebSocket.OPEN) {
          // Convert ArrayBuffer to base64
          const uint8Array = new Uint8Array(data);
          const base64Data = btoa(String.fromCharCode.apply(null, uint8Array));
          
          ws.send(JSON.stringify({
            type: 'audio_chunk',
            data: base64Data
          }));
        }
      };

      source.connect(workletNode);
      workletNode.connect(audioContext.destination);
    }

    function setupScriptProcessor() {
      const source = audioContext.createMediaStreamSource(stream);
      scriptNode = audioContext.createScriptProcessor(4096, 1, 1);

      scriptNode.onaudioprocess = function(e) {
        if (!sessionActive) return;

        const inputBuffer = e.inputBuffer;
        const inputData = inputBuffer.getChannelData(0);
        const buffer = new Int16Array(inputData.length);

        for (let i = 0; i < buffer.length; i++) {
          buffer[i] = Math.min(32767, Math.max(-32768, inputData[i] * 32768));
        }

        if (ws && ws.readyState === WebSocket.OPEN) {
          // Convert Int16Array to base64 for transmission
          const uint8Array = new Uint8Array(buffer.buffer);
          const base64Data = btoa(String.fromCharCode.apply(null, uint8Array));
          
          ws.send(JSON.stringify({
            type: 'audio_chunk',
            data: base64Data
          }));
        }
      };

      source.connect(scriptNode);
      scriptNode.connect(audioContext.destination);
    }

    function processVideo() {
      if (!sessionActive) {
        if (animationFrameId) {
          cancelAnimationFrame(animationFrameId);
          animationFrameId = null;
        }
        return;
      }

      if (video.readyState >= 2) { // HAVE_CURRENT_DATA
        const canvas = document.createElement('canvas');
        const ctx = canvas.getContext('2d');
        canvas.width = video.videoWidth || 640;
        canvas.height = video.videoHeight || 480;
        
        ctx.drawImage(video, 0, 0);

        if (ws && ws.readyState === WebSocket.OPEN) {
          canvas.toBlob(blob => {
            if (blob && sessionActive) {
              const reader = new FileReader();
              reader.onload = () => {
                if (ws && ws.readyState === WebSocket.OPEN && sessionActive) {
                  ws.send(JSON.stringify({
                    type: 'video_frame',
                    data: reader.result.split(',')[1]
                  }));
                }
              };
              reader.readAsDataURL(blob);
            }
          }, 'image/jpeg', 0.7);
        }
      }

      animationFrameId = requestAnimationFrame(processVideo);
    }

    function stopDetection() {
      sessionActive = false;
      connectionAttempts = 0;

      if (animationFrameId) {
        cancelAnimationFrame(animationFrameId);
        animationFrameId = null;
      }

      if (scriptNode) {
        scriptNode.disconnect();
        scriptNode = null;
      }

      if (audioContext && audioContext.state !== 'closed') {
        audioContext.close();
        audioContext = null;
      }

      if (stream) {
        stream.getTracks().forEach(track => track.stop());
        stream = null;
        video.srcObject = null;
      }

      if (ws) {
        if (ws.readyState === WebSocket.OPEN) {
          ws.send(JSON.stringify({ type: 'stop_session' }));
        }
        ws.close();
        ws = null;
      }

      startBtn.disabled = false;
      stopBtn.disabled = true;
    }

    startBtn.addEventListener('click', startDetection);
    stopBtn.addEventListener('click', stopDetection);

    initEmotionDisplays();

    // Handle page visibility changes
    document.addEventListener('visibilitychange', () => {
      if (document.hidden && sessionActive) {
        console.log('Page hidden, pausing detection');
      } else if (!document.hidden && sessionActive) {
        console.log('Page visible, resuming detection');
      }
    });
  </script>
</body>
</html>
